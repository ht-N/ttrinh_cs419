{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\miniconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in d:\\miniconda3\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in d:\\miniconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\miniconda3\\lib\\site-packages (from nltk) (2023.3.23)\n",
      "Requirement already satisfied: joblib in d:\\miniconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: colorama in d:\\miniconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.7.1-py3-none-any.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 589.1 kB/s eta 0:00:00\n",
      "Installing collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_NUM=1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Define the corpus\n",
    "corpus=[]\n",
    "for i in range(1,1400):\n",
    "    with open(f\"./Cranfield/{i}.txt\", \"r\") as f:\n",
    "        corpus.append(f.read())\n",
    "\n",
    "# Tokenize the documents and remove stopwords and punctuation\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [stemmer.stem(token) for token in tokens if token not in stopwords and token not in string.punctuation]\n",
    "    return tokens\n",
    "\n",
    "tokenized_corpus = [preprocess(text) for text in corpus]\n",
    "\n",
    "# Build the document-term matrix\n",
    "terms = set([token for doc in tokenized_corpus for token in doc])\n",
    "term_index = {term: i for i, term in enumerate(sorted(terms))}\n",
    "doc_term_matrix = np.zeros((len(tokenized_corpus), len(terms)))\n",
    "\n",
    "for i, doc in enumerate(tokenized_corpus):\n",
    "    for token in doc:\n",
    "        j = term_index[token]\n",
    "        doc_term_matrix[i, j] += 1\n",
    "\n",
    "# Calculate the IDF values\n",
    "doc_freq = np.sum(doc_term_matrix > 0, axis=0)\n",
    "idf = np.log(len(tokenized_corpus) / doc_freq)\n",
    "\n",
    "# Calculate the TF-IDF matrix\n",
    "tfidf = np.zeros_like(doc_term_matrix, dtype=float)\n",
    "for i in range(len(tokenized_corpus)):\n",
    "    tfidf[i] = doc_term_matrix[i] * idf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 31\t2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(f'./RES/{1}.txt','r') as f:\n",
    "    print(f.readlines()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add score for each queries\n",
    "true_answer={}\n",
    "for i in range(1,225+1):\n",
    "    with open(f'./RES/{i}.txt','r') as f:\n",
    "        true_answer[i]={}\n",
    "        for line in f.readlines():\n",
    "            temp=line.replace(\" \",\"\\t\").split()\n",
    "            if(len(temp)<3):\n",
    "                continue\n",
    "            _,index,points=temp\n",
    "            index,points=int(index),int(points)\n",
    "            if(points==-1):\n",
    "                true_answer[i][index]=1\n",
    "            elif points==1:\n",
    "                true_answer[i][index]=0.8\n",
    "            elif points==2:\n",
    "                true_answer[i][index]=0.7\n",
    "            elif points==3:\n",
    "                true_answer[i][index]=0.6\n",
    "            elif points==4:\n",
    "                true_answer[i][index]=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add queries from folder\n",
    "queries=[]\n",
    "queries.append(\"\")\n",
    "with open(f'./query.txt','r') as f:\n",
    "    for line in f.readlines():\n",
    "        queries.append(line[2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jakiro\\AppData\\Local\\Temp\\ipykernel_12792\\894788197.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  similarity_scores = np.dot(tfidf, query_tfidf) / (np.linalg.norm(tfidf, axis=1) * np.linalg.norm(query_tfidf))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores={0:0}\n",
    "for u,query in enumerate(queries[1:]):\n",
    "    i=u+1\n",
    "    scores[i]=0\n",
    "    # Search for documents that contain a query term\n",
    "    query_tokens = preprocess(query)\n",
    "    query_vector = np.zeros(len(terms))\n",
    "    if(len(query_tokens)==0):\n",
    "        continue\n",
    "    for token in query_tokens:\n",
    "        if token in term_index:\n",
    "            j = term_index[token]\n",
    "            query_vector[j] += 1\n",
    "\n",
    "    query_tfidf = query_vector * idf\n",
    "    \n",
    "    similarity_scores = np.dot(tfidf, query_tfidf) / (np.linalg.norm(tfidf, axis=1) * np.linalg.norm(query_tfidf))\n",
    "\n",
    "    # Rank the documents by their similarity scores\n",
    "    ranking = similarity_scores.argsort()[-20:][::-1]+1\n",
    "\n",
    "    for rank in ranking:\n",
    "        scores[i]+=true_answer[i].get(rank,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 5.1,\n",
       " 2: 4.0,\n",
       " 3: 5.199999999999999,\n",
       " 4: 2.2,\n",
       " 5: 2.2,\n",
       " 6: 2.3,\n",
       " 7: 2.2,\n",
       " 8: 4.6,\n",
       " 9: 0,\n",
       " 10: 2.9,\n",
       " 11: 2.6,\n",
       " 12: 2.9000000000000004,\n",
       " 13: 1,\n",
       " 14: 1.3,\n",
       " 15: 1.4,\n",
       " 16: 1.6,\n",
       " 17: 1.7,\n",
       " 18: 1.7,\n",
       " 19: 0,\n",
       " 20: 5.799999999999999,\n",
       " 21: 3.2,\n",
       " 22: 0,\n",
       " 23: 5.800000000000001,\n",
       " 24: 2.4,\n",
       " 25: 4.3,\n",
       " 26: 2.3,\n",
       " 27: 1.7,\n",
       " 28: 0,\n",
       " 29: 3.0999999999999996,\n",
       " 30: 1,\n",
       " 31: 1,\n",
       " 32: 1,\n",
       " 33: 2.1,\n",
       " 34: 4.2,\n",
       " 35: 0,\n",
       " 36: 0.6,\n",
       " 37: 4.2,\n",
       " 38: 1.6,\n",
       " 39: 3.2,\n",
       " 40: 2.2,\n",
       " 41: 2.3,\n",
       " 42: 2.9,\n",
       " 43: 3.6000000000000005,\n",
       " 44: 0,\n",
       " 45: 3.0,\n",
       " 46: 3.8000000000000003,\n",
       " 47: 5.7,\n",
       " 48: 2.3,\n",
       " 49: 1.6,\n",
       " 50: 0.7,\n",
       " 51: 4.8,\n",
       " 52: 3.5999999999999996,\n",
       " 53: 1.6,\n",
       " 54: 1.7,\n",
       " 55: 3.0999999999999996,\n",
       " 56: 2.6,\n",
       " 57: 2.1,\n",
       " 58: 1,\n",
       " 59: 1.2,\n",
       " 60: 2.7,\n",
       " 61: 3.0,\n",
       " 62: 0.6,\n",
       " 63: 0,\n",
       " 64: 2.5,\n",
       " 65: 4.8999999999999995,\n",
       " 66: 2.0,\n",
       " 67: 6.699999999999999,\n",
       " 68: 1.7,\n",
       " 69: 1,\n",
       " 70: 1.7,\n",
       " 71: 1.8,\n",
       " 72: 2.3,\n",
       " 73: 5.3999999999999995,\n",
       " 74: 1.2,\n",
       " 75: 0.6,\n",
       " 76: 2.9,\n",
       " 77: 4.5,\n",
       " 78: 2.9000000000000004,\n",
       " 79: 1,\n",
       " 80: 1,\n",
       " 81: 2.3,\n",
       " 82: 1.2999999999999998,\n",
       " 83: 0,\n",
       " 84: 2.2,\n",
       " 85: 0,\n",
       " 86: 2.2,\n",
       " 87: 1,\n",
       " 88: 4.8,\n",
       " 89: 1.9,\n",
       " 90: 1.6,\n",
       " 91: 3.1,\n",
       " 92: 6.3999999999999995,\n",
       " 93: 1.6,\n",
       " 94: 3.3,\n",
       " 95: 2.3,\n",
       " 96: 4.1,\n",
       " 97: 1.6,\n",
       " 98: 1,\n",
       " 99: 3.0,\n",
       " 100: 3.0,\n",
       " 101: 5.0,\n",
       " 102: 2.4,\n",
       " 103: 1.6,\n",
       " 104: 2.2,\n",
       " 105: 2.6,\n",
       " 106: 2.2,\n",
       " 107: 2.7,\n",
       " 108: 5.3,\n",
       " 109: 1,\n",
       " 110: 0.8,\n",
       " 111: 4.199999999999999,\n",
       " 112: 1.5,\n",
       " 113: 1.2,\n",
       " 114: 1.8,\n",
       " 115: 1,\n",
       " 116: 0.6,\n",
       " 117: 0,\n",
       " 118: 1.2999999999999998,\n",
       " 119: 1.5,\n",
       " 120: 5.3999999999999995,\n",
       " 121: 4.8999999999999995,\n",
       " 122: 3.2,\n",
       " 123: 1.7,\n",
       " 124: 1,\n",
       " 125: 3.0,\n",
       " 126: 2.4,\n",
       " 127: 1.6,\n",
       " 128: 1,\n",
       " 129: 3.6000000000000005,\n",
       " 130: 3.5,\n",
       " 131: 4.6,\n",
       " 132: 6.3999999999999995,\n",
       " 133: 2.9,\n",
       " 134: 2.3,\n",
       " 135: 4.8,\n",
       " 136: 1.8,\n",
       " 137: 3.5,\n",
       " 138: 1.8,\n",
       " 139: 1,\n",
       " 140: 2.6,\n",
       " 141: 1.4,\n",
       " 142: 1.8,\n",
       " 143: 1.6,\n",
       " 144: 4.8,\n",
       " 145: 3.3999999999999995,\n",
       " 146: 2.4000000000000004,\n",
       " 147: 3.3000000000000003,\n",
       " 148: 3.0,\n",
       " 149: 3.0,\n",
       " 150: 2.2,\n",
       " 151: 2.1,\n",
       " 152: 1,\n",
       " 153: 1,\n",
       " 154: 2.3,\n",
       " 155: 2.8,\n",
       " 156: 5.5,\n",
       " 157: 5.4,\n",
       " 158: 2.2,\n",
       " 159: 2.1,\n",
       " 160: 1.6,\n",
       " 161: 1.9,\n",
       " 162: 1.4,\n",
       " 163: 2.2,\n",
       " 164: 3.4000000000000004,\n",
       " 165: 2.6,\n",
       " 166: 1,\n",
       " 167: 0.7,\n",
       " 168: 2.6,\n",
       " 169: 3.4000000000000004,\n",
       " 170: 3.0,\n",
       " 171: 3.0999999999999996,\n",
       " 172: 3.8000000000000003,\n",
       " 173: 2.6,\n",
       " 174: 2.6,\n",
       " 175: 2.4,\n",
       " 176: 1,\n",
       " 177: 4.1,\n",
       " 178: 3.4000000000000004,\n",
       " 179: 1.6,\n",
       " 180: 2.7,\n",
       " 181: 0.6,\n",
       " 182: 2.4,\n",
       " 183: 6.199999999999999,\n",
       " 184: 2.8000000000000003,\n",
       " 185: 6.5,\n",
       " 186: 1.7999999999999998,\n",
       " 187: 2.7,\n",
       " 188: 3.7,\n",
       " 189: 2.2,\n",
       " 190: 2.8,\n",
       " 191: 7.0,\n",
       " 192: 3.4000000000000004,\n",
       " 193: 5.3999999999999995,\n",
       " 194: 2.8000000000000003,\n",
       " 195: 1.6,\n",
       " 196: 2.8,\n",
       " 197: 2.9,\n",
       " 198: 3.0,\n",
       " 199: 0,\n",
       " 200: 3.0999999999999996,\n",
       " 201: 3.1,\n",
       " 202: 3.8,\n",
       " 203: 2.2,\n",
       " 204: 1.9,\n",
       " 205: 2.4,\n",
       " 206: 2.4,\n",
       " 207: 0,\n",
       " 208: 3.3000000000000003,\n",
       " 209: 2.2,\n",
       " 210: 2.3,\n",
       " 211: 1.5,\n",
       " 212: 4.699999999999999,\n",
       " 213: 6.099999999999999,\n",
       " 214: 2.2,\n",
       " 215: 1,\n",
       " 216: 0,\n",
       " 217: 3.4,\n",
       " 218: 3.2,\n",
       " 219: 1.6,\n",
       " 220: 2.2,\n",
       " 221: 2.3000000000000003,\n",
       " 222: 3.8000000000000003,\n",
       " 223: 1.7999999999999998,\n",
       " 224: 2.2,\n",
       " 225: 1.5}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft  \"\n",
    "query_tokens = preprocess(query)\n",
    "query_vector = np.zeros(len(terms))\n",
    "\n",
    "for token in query_tokens:\n",
    "    if token in term_index:\n",
    "        j = term_index[token]\n",
    "        query_vector[j] += 1\n",
    "\n",
    "query_tfidf = query_vector * idf\n",
    "similarity_scores = np.dot(tfidf, query_tfidf) / (np.linalg.norm(tfidf, axis=1) * np.linalg.norm(query_tfidf))\n",
    "\n",
    "# Rank the documents by their similarity scores\n",
    "ranking = similarity_scores.argsort()[-20:][::-1]\n",
    "\n",
    "for i in ranking:\n",
    "    print(f\"Document {i+1}: {corpus[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
